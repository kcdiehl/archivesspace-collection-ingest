{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488cf94f",
   "metadata": {},
   "source": [
    "First, the script imports the Python packages/libraries needed to run script: pandas, json, argparse, uuid, & datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8af446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0b043",
   "metadata": {},
   "source": [
    "Then, the script uses argparse to let us enter a filename in our terminal when we run the script. \n",
    "\n",
    "```\n",
    "python makeArchivalObjects.py -f filename.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0544c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', '--file')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.file:\n",
    "    filename = args.file\n",
    "else:\n",
    "    filename = input('Enter filename (including \\'.csv\\'): ')\n",
    "filename = 'exampleSheets_archivalObjects.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16904b4e",
   "metadata": {},
   "source": [
    "Then, we see two functions:`add_to_dict` and `add_with_ref`. We can worry about these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b647fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(dict_name, key, value):\n",
    "    try:\n",
    "        value = row.get(value)\n",
    "        if pd.notna(value):\n",
    "            value = value.strip()\n",
    "            dict_name[key] = value\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def add_with_ref(dict_name, key, value, repeat):  \n",
    "    try:\n",
    "        value = row[value]\n",
    "        if pd.notna(value):\n",
    "            if repeat == 'single':\n",
    "                value = value.strip()\n",
    "                dict_name[key] = {'ref': value}\n",
    "            else:\n",
    "                new_list = []\n",
    "                value = value.split('|')\n",
    "                for item in value:\n",
    "                    new_dict = {'ref': item}\n",
    "                    new_list.append(new_dict)\n",
    "                dict_name[key] = new_list\n",
    "    \n",
    "    except KeyError:\n",
    "        pass\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82415b4",
   "metadata": {},
   "source": [
    "This next bit of code opens the CSV as a `DataFrame` called `df` and loops through its rows.\n",
    "\n",
    "As the script loops through each row, it extracts data based on CSV column names and adds the data to a dictionary called `json_file`. This dictionary will be transformed and saved as a JSON file at the end of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99778ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, dtype={'position': str, 'parent': str})\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # Create empty dictionary to store data.\n",
    "    json_file = {}\n",
    "    json_file['jsonmodel_type'] = 'archival_object'\n",
    "    json_file['suppressed'] = False\n",
    "    \n",
    "    # For required fields, add directly to json_file.\n",
    "    identifier = row['local_id']\n",
    "    json_file['title'] = row['title']\n",
    "    json_file['resource'] = {'ref': row['resource']}\n",
    "    json_file['level'] = row['level']\n",
    "    json_file['publish'] = row['publish']\n",
    "    json_file['restrictions_apply'] = row['restrictions_apply']\n",
    "    \n",
    "    # For optional fields, try to find value and add to json_file if found.\n",
    "    add_to_dict(json_file, 'repository_processing_note', 'repository_processing_note')\n",
    "    add_to_dict(json_file, 'position', 'position')\n",
    "    add_to_dict(json_file, 'other_level', 'other_level')\n",
    "    \n",
    "    # For optional fields with 'ref' key, use function to add.\n",
    "    add_with_ref(json_file, 'parent', 'parent', 'single')\n",
    "    add_with_ref(json_file, 'repository', 'repository', 'single')\n",
    "    add_with_ref(json_file, 'linked_events', 'linked_events', 'multi')\n",
    "    add_with_ref(json_file, 'subjects', 'subjects', 'multi')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e838f9",
   "metadata": {},
   "source": [
    "This section generates a filename (`ao_filename`) based on an identifier variable and a datetime stamp, and then uses the json function `json.dump` to write and save our dictionary into a JSON file using our unique `ao_filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1705942",
   "metadata": {},
   "outputs": [],
   "source": [
    "    dt = datetime.now().strftime('%Y-%m-%d')\n",
    "    ao_filename = identifier+'_'+dt+'.json'\n",
    "    directory = ''\n",
    "    with open(directory+ao_filename, 'w') as fp:\n",
    "        json.dump(json_file, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4b491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
